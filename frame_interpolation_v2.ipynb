{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsk245/frame_interpolator/blob/main/frame_interpolation_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc08hL2WeGD4"
      },
      "outputs": [],
      "source": [
        "!pip install dm-haiku optax scikit-video tfds-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU_poHhhjKjY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a-cw2VlePRL"
      },
      "outputs": [],
      "source": [
        "import haiku as hk\n",
        "import jax\n",
        "import optax\n",
        "import jax.numpy as jnp\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import requests\n",
        "import os\n",
        "import random\n",
        "import skvideo.io\n",
        "from functools import partial\n",
        "from typing import Any, NamedTuple\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "tf.config.set_visible_devices([], device_type='GPU')\n",
        "\n",
        "print(\"JAX version {}\".format(jax.__version__))\n",
        "print(\"Haiku version {}\".format(hk.__version__))\n",
        "print(\"TF version {}\".format(tf.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0InWWX3eTD1"
      },
      "outputs": [],
      "source": [
        "data_dir = '/tmp/tfds'\n",
        "\n",
        "# Fetch full datasets for evaluation\n",
        "# tfds.load returns tf.Tensors (or tf.data.Datasets if batch_size != -1)\n",
        "# You can convert them to NumPy arrays (or iterables of NumPy arrays) with tfds.dataset_as_numpy\n",
        "## there's also a validation split for more data to train on\n",
        "data, info = tfds.load(name=\"davis\", data_dir=data_dir, split=\"train\", with_info=True)\n",
        "\n",
        "## extra data to train on\n",
        "\"\"\"\n",
        "config = tfds.download.DownloadConfig(verify_ssl=False)\n",
        "data = tfds.load(name=\"ucf101\", split=\"train\", shuffle_files=True, data_dir=data_dir, download_and_prepare_kwargs={\"download_config\" : config})\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FXEzUPhghCId"
      },
      "outputs": [],
      "source": [
        "def make_dataset(data=data, shuffle_amount=2, batch_size=1):\n",
        "  def _to_float(sample_frames):\n",
        "    # Convert to floats in [0, 1].\n",
        "    sample = tf.image.convert_image_dtype(sample_frames, tf.float32)\n",
        "    # Scale the data to [-1, 1] to stabilize training.\n",
        "    sample = 2.0 * sample - 1.0\n",
        "    return sample\n",
        "  def _preprocess(sample):\n",
        "    sample_frames = sample[\"video\"][\"frames\"]\n",
        "    sample_frames = _to_float(sample_frames)\n",
        "    return sample_frames\n",
        "\n",
        "  ds = data\n",
        "  ds = ds.map(map_func=_preprocess, \n",
        "              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  ## increasing shuffle amount is more proper but it takes up more space\n",
        "  ds = ds.shuffle(shuffle_amount).repeat().batch(batch_size)\n",
        "  return (iter(tfds.as_numpy(ds)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "orpA7kU1ISMz"
      },
      "outputs": [],
      "source": [
        "def save(ckpt_dir: str, state) -> None:\n",
        " with open(os.path.join(ckpt_dir, \"arrays.npy\"), \"wb\") as f:\n",
        "   for x in jax.tree_util.tree_leaves(state):\n",
        "     np.save(f, x, allow_pickle=False)\n",
        "\n",
        " tree_struct = jax.tree_map(lambda t: 0, state)\n",
        " with open(os.path.join(ckpt_dir, \"tree.pkl\"), \"wb\") as f:\n",
        "   pickle.dump(tree_struct, f)\n",
        "\n",
        "def restore(ckpt_dir):\n",
        " with open(os.path.join(ckpt_dir, \"tree.pkl\"), \"rb\") as f:\n",
        "   tree_struct = pickle.load(f)\n",
        " \n",
        " leaves, treedef = jax.tree_util.tree_flatten(tree_struct)\n",
        " with open(os.path.join(ckpt_dir, \"arrays.npy\"), \"rb\") as f:\n",
        "   flat_state = [np.load(f) for _ in leaves]\n",
        "\n",
        " return jax.tree_util.tree_unflatten(treedef, flat_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "okZM6Lt_yYXr"
      },
      "outputs": [],
      "source": [
        "## using more than two surrounding frames should generate better results\n",
        "def process_data(sample_frames, vary_frame_distance=False, use_adjustments=False):\n",
        "  ## maybe adjust the random cutoffs\n",
        "  ## maybe add adjustments affecting color\n",
        "  if use_adjustments: # will flip image left/right and play frames in reverse randomly\n",
        "    is_tensor = False\n",
        "    if random.random() < 0.25:\n",
        "      sample_frames = tf.image.flip_up_down(sample_frames)\n",
        "      is_tensor = True\n",
        "    if random.random() < 0.25:\n",
        "      sample_frames = tf.image.flip_left_right(sample_frames)\n",
        "      is_tensor = True\n",
        "    if is_tensor:\n",
        "      sample_frames = tfds.as_numpy(sample_frames)\n",
        "    if random.random() < 0.25:\n",
        "      sample_frames = jnp.flip(sample_frames, axis=0)\n",
        "  key = jax.random.PRNGKey(random.randint(0,1000))\n",
        "  if vary_frame_distance: #will randomly choose to use frames from further away to predict one in the center\n",
        "    ## maybe increase the spread if the videos trained on have high frame rates\n",
        "    distance_spread = random.randint(1,3)\n",
        "  else:\n",
        "    distance_spread = 1\n",
        "  idx = jax.random.randint(key, [1], distance_spread, sample_frames.shape[0]-distance_spread)\n",
        "  idx = jnp.repeat(idx, 3)\n",
        "  idx = idx + jnp.tile(jnp.arange(-1*distance_spread,2*distance_spread, distance_spread), 1)\n",
        "  idx = jnp.clip(idx, a_min=0, a_max=sample_frames.shape[0]-1)\n",
        "  idx = jax.device_get(idx)\n",
        "  sample = sample_frames[idx, :]\n",
        "  if use_adjustments and random.random() < 0.5: # for making random 256x256 crops of the image\n",
        "    ## maybe allow smaller portions to be cropped. Right now the smallest crop possible always includes the middle 50% of pixels\n",
        "    x1 = random.random()/4\n",
        "    x2 = random.random()/4 + 0.75\n",
        "    y1 = random.random()/4\n",
        "    y2 = random.random()/4 + 0.75\n",
        "    crops = jnp.reshape(jnp.tile(jnp.array((y1, x1, y2, x2)), 1*3), (1*3, 4))\n",
        "  else:\n",
        "    crops = jnp.reshape(jnp.tile(jnp.array((0, 0, 1, 1)), 1*3), (1*3, 4))\n",
        "  sample = tf.image.crop_and_resize(\n",
        "            sample,\n",
        "            crops,\n",
        "            jnp.arange(1*3),\n",
        "            (256, 256)).numpy()\n",
        "  sample = jnp.reshape(sample, [1,3] + list(sample.shape[1:]))\n",
        "  goal_frames = sample[:,1,:,:,:]\n",
        "  goal_frames = jnp.reshape(goal_frames, [1,1] + list(sample.shape[2:]))\n",
        "  sample = jnp.delete(sample, 1, axis=1)\n",
        "  return sample, goal_frames\n",
        "\n",
        "def make_batch(dataset, vary_frame_distance=False, use_adjustments=False, batch_size=4, skip_prob=0.5):\n",
        "  surrounding_frames = jnp.empty((0, 2, 256, 256, 3))\n",
        "  goal_frames = jnp.empty((0, 1, 256, 256, 3))\n",
        "  for i in range(batch_size):\n",
        "    data = next(dataset)[0]\n",
        "    rand_val = random.random()\n",
        "    if rand_val > (1-skip_prob):\n",
        "      data = next(dataset)[0]\n",
        "      rand_val = random.random()\n",
        "    next_surrounding, next_goal = process_data(data, vary_frame_distance, use_adjustments)\n",
        "    surrounding_frames = jnp.concatenate([surrounding_frames, next_surrounding])\n",
        "    goal_frames = jnp.concatenate([goal_frames, next_goal])\n",
        "  return surrounding_frames, goal_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CdtSCPmkHSs-"
      },
      "outputs": [],
      "source": [
        "# useful if using attention\n",
        "\"\"\"def positional_encoding(input_tensor):\n",
        "  encoding = jnp.ones(input_tensor.shape)\n",
        "  first_helper = encoding[:,:,:,:encoding.shape[-1]//3] * jnp.arange(encoding.shape[0])[:,None,None,None]\n",
        "  second_helper = encoding[:,:,:,encoding.shape[-1]//3:2*encoding.shape[-1]//3] * jnp.arange(encoding.shape[1])[None,:,None,None]\n",
        "  third_helper = encoding[:,:,:,2*encoding.shape[-1]//3:] * jnp.arange(encoding.shape[2])[None,None,:,None]\n",
        "  encoding = (jnp.concatenate([first_helper, second_helper, third_helper], axis=-1))\n",
        "\n",
        "  encoding_helper = jnp.ones(encoding.shape)\n",
        "  first_helper = encoding_helper[:,:,:,:encoding.shape[-1]//3]\n",
        "  second_helper = encoding_helper[:,:,:,encoding.shape[-1]//3:2*encoding.shape[-1]//3]\n",
        "  third_helper = encoding_helper[:,:,:,2*encoding.shape[-1]//3:]\n",
        "  first_helper = first_helper * jnp.repeat(jnp.arange((first_helper.shape[-1])//2+1), 2)[None,None,None,:first_helper.shape[-1]]\n",
        "  second_helper = second_helper * jnp.repeat(jnp.arange((second_helper.shape[-1])//2+1), 2)[None,None,None,:second_helper.shape[-1]]\n",
        "  third_helper = third_helper * jnp.repeat(jnp.arange((third_helper.shape[-1])//2+1), 2)[None,None,None,:third_helper.shape[-1]]\n",
        "  encoding_helper = (jnp.concatenate([first_helper, second_helper, third_helper], axis=-1))\n",
        "  encoding_helper = 10000 ** (encoding_helper * 6 / encoding_helper.shape[-1])\n",
        "\n",
        "  encoding = encoding / encoding_helper\n",
        "  encoding = encoding.at[:,:,:,::2].set(jnp.sin(encoding[:,:,:,::2]))\n",
        "  encoding = encoding.at[:,:,:,1::2].set(jnp.cos(encoding[:,:,:,1::2]))\n",
        "  return input_tensor + encoding\"\"\"\n",
        "\n",
        "class FourierConv(hk.Module):\n",
        "  def __init__(self, channels, conv_length, is_training, temporal=True, name=None):\n",
        "    super(FourierConv, self).__init__(name=name)\n",
        "    hidden_channels = channels//2\n",
        "    self.conv1 = hk.ConvND(3, hidden_channels, 1, 1)\n",
        "    self.bn1 = hk.BatchNorm(False, False, 0.9, cross_replica_axis=\"jax_vmap_fourier\")\n",
        "\n",
        "    if temporal:\n",
        "      self.conv2 = hk.ConvND(3, channels, [2,conv_length,conv_length], 1)\n",
        "    else:\n",
        "      self.conv2 = hk.ConvND(3, channels, [1,conv_length,conv_length], 1)\n",
        "    self.bn2 = hk.BatchNorm(False, False, 0.9, cross_replica_axis=\"jax_vmap_fourier\")\n",
        "    \n",
        "    self.conv3 = hk.ConvND(3, channels, 1, 1)\n",
        "\n",
        "    self.is_training = is_training\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x, self.is_training)\n",
        "    x = jax.nn.relu(x)\n",
        "    x_res = x\n",
        "    x = jnp.fft.rfftn(x, axes=(0,1,2))\n",
        "    x = jnp.reshape(jnp.stack([x.real, x.imag], axis=-1), (x.shape[0], x.shape[1], x.shape[2], x.shape[3]*2))\n",
        "    x = self.conv2(x)\n",
        "    x = x=self.bn2(x, self.is_training)\n",
        "    x = jax.nn.relu(x)\n",
        "    x = jnp.reshape(x, (x.shape[0], x.shape[1], x.shape[2], x.shape[3]//2, 2))\n",
        "    x = jax.lax.complex(x[:,:,:,:,0], x[:,:,:,:,1])\n",
        "    x = jnp.fft.irfftn(x, axes=(0,1,2))\n",
        "    x = x + x_res\n",
        "    x = jax.nn.relu(self.conv3(x))\n",
        "    return x\n",
        "\n",
        "class FourierBlock(hk.Module):\n",
        "  def __init__(self, channels, is_training, temporal=True, name=None):\n",
        "    super(FourierBlock, self).__init__(name=name)\n",
        "    self.channels = channels\n",
        "    half = channels//2\n",
        "\n",
        "    self.conv_local_1 = hk.Conv2D(half, 3, 1)\n",
        "    self.fourier_local = FourierConv(half, 3, is_training, temporal)\n",
        "    self.local_bn = hk.BatchNorm(False, False, 0.9, cross_replica_axis=\"jax_vmap_fourier\")\n",
        "\n",
        "    self.fourier_global_1 = hk.Conv3D(half, [2,3,3], 1)\n",
        "    self.fourier_global_2 = FourierConv(half, 3, is_training, temporal)\n",
        "    self.global_bn = hk.BatchNorm(False, False, 0.9, cross_replica_axis=\"jax_vmap_fourier\")\n",
        "\n",
        "    self.is_training = is_training\n",
        "\n",
        "  def __call__(self, x):\n",
        "    split = self.channels // 2\n",
        "    local_side = x[:,:,:,0:split]\n",
        "    global_side = x[:,:,:,split:]\n",
        "    pure_local = self.conv_local_1(local_side)\n",
        "    N, H, W, C = local_side.shape\n",
        "    q1 = self.fourier_local(local_side[:,:H//2,:W//2,:])\n",
        "    q2 = self.fourier_local(local_side[:,:H//2,W//2:,:])\n",
        "    q3 = self.fourier_local(local_side[:,H//2:,:W//2,:])\n",
        "    q4 = self.fourier_local(local_side[:,H//2:,W//2:,:])\n",
        "    local_to_global = jnp.reshape(jnp.concatenate([q1, q2, q3, q4], axis=2), (N,H,W,C))\n",
        "    local_to_global = jnp.concatenate([local_to_global[:,::2,:,:], local_to_global[:,1::2,:,:]], axis=1)\n",
        "\n",
        "    global_to_local = self.fourier_global_1(global_side)\n",
        "    ## replace this with a regular conv to test if the fourier is helping\n",
        "    pure_global = self.fourier_global_2(global_side)\n",
        "    local_side = pure_local + global_to_local\n",
        "    global_side = local_to_global + pure_global\n",
        "    local_side = jax.nn.relu(self.local_bn(local_side, self.is_training))\n",
        "    global_side = jax.nn.relu(self.global_bn(global_side, self.is_training))\n",
        "    x = jnp.reshape(jnp.stack([local_side, global_side], axis=-1), (x.shape[0], x.shape[1], x.shape[2], self.channels))\n",
        "    ## dropout?\n",
        "    return x\n",
        "\n",
        "class MyChannelMatcher(hk.Module):\n",
        "\n",
        "  def __init__(self, out_channels, name=None):\n",
        "    super(MyChannelMatcher, self).__init__(name=name)\n",
        "    self.out_channels = out_channels\n",
        "\n",
        "  def __call__(self, x):\n",
        "    N, num_frames, H, W, C = x.shape\n",
        "    w_init = hk.initializers.TruncatedNormal(1. / np.sqrt(num_frames*H*W*C))\n",
        "    w = hk.get_parameter(\"w\", shape=[1, 1, 1, C, self.out_channels], dtype=x.dtype, init=w_init)\n",
        "    dn = jax.lax.conv_dimension_numbers(x.shape, w.shape, ('NDHWC', 'HWDIO', 'NDHWC'))\n",
        "    out = jax.lax.conv_general_dilated(x,    # lhs = image tensor\n",
        "                               w,  # rhs = conv kernel tensor\n",
        "                               (1,1,1), # window strides\n",
        "                               'SAME',  # padding mode\n",
        "                               (1,1,1), # lhs/image dilation\n",
        "                               (1,1,1), # rhs/kernel dilation\n",
        "                               dn)      # dimension_numbers\n",
        "    return out\n",
        "\n",
        "class Padder(hk.Module):\n",
        "  def __init__(self, name=None):\n",
        "    super(Padder, self).__init__(name=name)\n",
        "\n",
        "  def __call__(self, x, x_res_future):\n",
        "    h_diff = x_res_future.shape[2] - x.shape[2]\n",
        "    h_diff_1 = h_diff//2\n",
        "    h_diff_2 = h_diff-h_diff_1\n",
        "    w_diff = x_res_future.shape[3] - x.shape[3]\n",
        "    w_diff_1 = w_diff//2\n",
        "    w_diff_2 = w_diff-w_diff_1\n",
        "    x = jnp.pad(x, ((0,0),(0,0),(h_diff_1,h_diff_2),(w_diff_1,w_diff_2),(0,0)))\n",
        "    return x\n",
        "\n",
        "class FConvBlock(hk.Module):\n",
        "  def __init__(self, channels, is_training, name=None):\n",
        "    super(FConvBlock, self).__init__(name=name)\n",
        "    self.conv = MyChannelMatcher(channels)\n",
        "    self.fourier_1 = FourierBlock(channels, is_training)\n",
        "    self.ln_1 = hk.LayerNorm(axis=-1, create_scale=False, create_offset=False)\n",
        "    self.fourier_2 = FourierBlock(channels, is_training)\n",
        "    self.ln_2 = hk.LayerNorm(axis=-1, create_scale=False, create_offset=False)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = jax.nn.relu(self.conv(x))\n",
        "    fourier_1 = partial(self.fourier_1)\n",
        "    x = self.ln_1(jax.vmap(fourier_1, axis_name=\"jax_vmap_fourier\")(x=x) + x)\n",
        "    \n",
        "    fourier_2 = partial(self.fourier_2)\n",
        "    x = self.ln_2(jax.vmap(fourier_2, axis_name=\"jax_vmap_fourier\")(x=x) + x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class Downsampler(hk.Module):\n",
        "  def __init__(self, is_training, name=None):\n",
        "    super(Downsampler, self).__init__(name=name)\n",
        "    self.avg_pooler = hk.AvgPool(2, 2, \"VALID\", channel_axis=-1)\n",
        "\n",
        "    self.fconv_block_downsample_1 = FConvBlock(32, is_training)\n",
        "    self.fconv_block_downsample_2 = FConvBlock(64, is_training)\n",
        "    self.fconv_block_downsample_3 = FConvBlock(128, is_training)\n",
        "\n",
        "\n",
        "  def __call__(self, x):\n",
        "    avg_pooler = partial(self.avg_pooler)\n",
        "\n",
        "    original_image = x\n",
        "    x = self.fconv_block_downsample_1(x)\n",
        "    x_res1 = x\n",
        "\n",
        "    x = jax.vmap(avg_pooler)(x)\n",
        "    original_image = jax.image.resize(original_image, list(x.shape[:-1]) + [3], \"bilinear\")\n",
        "    x = self.fconv_block_downsample_2(x)\n",
        "    x2 = self.fconv_block_downsample_1(original_image)\n",
        "    x_res2 = jax.numpy.concatenate([x, x2], axis=-1)\n",
        "\n",
        "    x = jax.vmap(avg_pooler)(x)\n",
        "    x2 = jax.vmap(avg_pooler)(x2)\n",
        "    original_image = jax.image.resize(original_image, list(x.shape[:-1]) + [3], \"bilinear\")\n",
        "    x = self.fconv_block_downsample_3(x)\n",
        "    x2 = self.fconv_block_downsample_2(x2)\n",
        "    x3 = self.fconv_block_downsample_1(original_image)\n",
        "    original_image = None\n",
        "    x_res3 = jax.numpy.concatenate([x, x2, x3], axis=-1)\n",
        "\n",
        "    x = jax.vmap(avg_pooler)(x2)\n",
        "    x2 = jax.vmap(avg_pooler)(x3)\n",
        "    x = self.fconv_block_downsample_3(x)\n",
        "    x2 = self.fconv_block_downsample_2(x2)\n",
        "    x_res4 = jax.numpy.concatenate([x, x2], axis=-1)\n",
        "\n",
        "    x = jax.vmap(avg_pooler)(x2)\n",
        "    x = self.fconv_block_downsample_3(x)\n",
        "    x_res5 = x\n",
        "\n",
        "    return (x_res1, x_res2, x_res3, x_res4, x_res5)\n",
        "\n",
        "class FConvBlockFlow(hk.Module):\n",
        "  def __init__(self, channels, is_training, name=None):\n",
        "    super(FConvBlockFlow, self).__init__(name=name)\n",
        "    self.fourier_1_and_2 = FConvBlock(channels, is_training)\n",
        "    self.fourier_3 = FourierBlock(channels, is_training)\n",
        "    self.ln_3 = hk.LayerNorm(axis=-1, create_scale=False, create_offset=False)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = self.fourier_1_and_2(x)\n",
        "\n",
        "    fourier_3 = partial(self.fourier_3)\n",
        "    x = self.ln_3(jax.vmap(fourier_3, axis_name=\"jax_vmap_fourier\")(x=x) + x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class Combiner(hk.Module):\n",
        "  def __init__(self, is_training, name=None):\n",
        "    super(Combiner, self).__init__(name=name)\n",
        "    self.fconv_block_flow_1 = FConvBlockFlow(32, is_training)\n",
        "    self.fconv_block_flow_2 = FConvBlockFlow(96, is_training)\n",
        "    self.fconv_block_flow_3 = FConvBlockFlow(224, is_training)\n",
        "\n",
        "    self.channel_matcher_res_5 = MyChannelMatcher(224)\n",
        "    self.channel_matcher_res_4 = MyChannelMatcher(224)\n",
        "    self.channel_matcher_res_2 = MyChannelMatcher(96)\n",
        "    self.channel_matcher_res_1 = MyChannelMatcher(32)\n",
        "\n",
        "    self.ln_res_4 = hk.LayerNorm(axis=-1, create_scale=False, create_offset=False)\n",
        "    self.ln_res_3 = hk.LayerNorm(axis=-1, create_scale=False, create_offset=False)\n",
        "    self.ln_res_2 = hk.LayerNorm(axis=-1, create_scale=False, create_offset=False)\n",
        "    self.ln_res_1 = hk.LayerNorm(axis=-1, create_scale=False, create_offset=False)\n",
        "\n",
        "    self.padder = Padder()\n",
        "\n",
        "  def __call__(self, x_res1, x_res2, x_res3, x_res4, x_res5):\n",
        "    x_res5 = jax.nn.relu(self.channel_matcher_res_5(x_res5))\n",
        "    x_res5 = self.fconv_block_flow_3(x_res5)\n",
        "    x = x_res5\n",
        "\n",
        "    x_res4 = jax.nn.relu(self.channel_matcher_res_4(x_res4))\n",
        "    x_res4 = self.fconv_block_flow_3(x_res4)\n",
        "    x = self.padder(x, x_res4)\n",
        "    x_res4 = self.ln_res_4(x_res4 + x)\n",
        "    x = x_res4\n",
        "\n",
        "    x_res3 = self.fconv_block_flow_3(x_res3)\n",
        "    x = self.padder(x, x_res3)\n",
        "    x_res3 = self.ln_res_3(x_res3 + x)\n",
        "    x = x_res3\n",
        "\n",
        "    x_res2 = self.fconv_block_flow_2(x_res2)\n",
        "    x = self.padder(x, x_res2)\n",
        "    x = self.channel_matcher_res_2(x)\n",
        "    x_res2 = self.ln_res_2(x_res2 + x)\n",
        "    x = x_res2\n",
        "\n",
        "    x_res1 = self.fconv_block_flow_1(x_res1)\n",
        "    x = self.padder(x, x_res1)\n",
        "    x = self.channel_matcher_res_1(x)\n",
        "    x_res1 = self.ln_res_1(x_res1 + x)\n",
        "\n",
        "    return (x_res1, x_res2, x_res3, x_res4, x_res5)\n",
        "\n",
        "class FConvBlockUpsample(hk.Module):\n",
        "  def __init__(self, channels, is_training, name=None):\n",
        "    super(FConvBlockUpsample, self).__init__(name=name)\n",
        "    self.fourier_conv = FConvBlock(channels, is_training)\n",
        "\n",
        "    self.upsample_conv = hk.ConvNDTranspose(2, channels, 2, stride=2)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = self.fourier_conv(x)\n",
        "\n",
        "    upsample = partial(self.upsample_conv)\n",
        "    x = jax.nn.relu(jax.vmap(upsample)(x))\n",
        "\n",
        "    return x\n",
        "\n",
        "class Upsampler(hk.Module):\n",
        "  def __init__(self, is_training, name=None):\n",
        "    super(Upsampler, self).__init__(name=name)\n",
        "    self.fconv_block_upsample_5 = FConvBlockUpsample(224, is_training)\n",
        "    self.fconv_block_upsample_4 = FConvBlockUpsample(128, is_training)\n",
        "    self.fconv_block_upsample_3 = FConvBlock(64, is_training)\n",
        "    self.fconv_block_upsample_2 = FConvBlock(32, is_training)\n",
        "\n",
        "    self.padder = Padder()\n",
        "\n",
        "  def __call__(self, x_res1, x_res2, x_res3, x_res4, x_res5):\n",
        "    x_res5 = jnp.maximum(x_res5[:,0,:,:,:], x_res5[:,1,:,:,:])[:,None,:,:,:]\n",
        "    x_res5 = self.fconv_block_upsample_5(x_res5)\n",
        "    x_res5 = self.padder(x_res5, x_res4)\n",
        "\n",
        "    x_res4 = jnp.concatenate([jnp.maximum(x_res4[:,0,:,:,:], x_res4[:,1,:,:,:])[:,None,:,:,:], x_res5], axis=-1)\n",
        "    x_res4 = self.fconv_block_upsample_4(x_res4)\n",
        "    x_res4 = self.padder(x_res4, x_res3)\n",
        "\n",
        "    x_res3 = jnp.concatenate([jnp.maximum(x_res3[:,0,:,:,:], x_res3[:,1,:,:,:])[:,None,:,:,:], x_res4], axis=-1)\n",
        "    x_res3 = self.fconv_block_upsample_3(x_res3)\n",
        "    x_res3 = self.padder(x_res3, x_res2)\n",
        "\n",
        "    x_res2 = jnp.concatenate([jnp.maximum(x_res2[:,0,:,:,:], x_res2[:,1,:,:,:])[:,None,:,:,:], x_res3], axis=-1)\n",
        "    x_res2 = self.fconv_block_upsample_2(x_res2)\n",
        "    x_res2 = self.padder(x_res2, x_res1)\n",
        "\n",
        "    x = jnp.concatenate([jnp.maximum(x_res1[:,0,:,:,:], x_res1[:,1,:,:,:])[:,None,:,:,:], x_res2], axis=-1)\n",
        "\n",
        "    return x\n",
        "\n",
        "class ImageGenerator(hk.Module):\n",
        "  def __init__(self, is_training, name=None):\n",
        "    super(ImageGenerator, self).__init__(name=name)\n",
        "\n",
        "    self.downsampler = Downsampler(is_training)\n",
        "\n",
        "    self.combiner = Combiner(is_training)\n",
        "\n",
        "    self.upsampler = Upsampler(is_training)\n",
        "\n",
        "    self.final_conv = hk.ConvNDTranspose(3, 3, [1,3,3], 1)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x_res1, x_res2, x_res3, x_res4, x_res5 = self.downsampler(x)\n",
        "\n",
        "    x_res1, x_res2, x_res3, x_res4, x_res5 = self.combiner(x_res1, x_res2, x_res3, x_res4, x_res5)\n",
        "\n",
        "    x = self.upsampler(x_res1, x_res2, x_res3, x_res4, x_res5)\n",
        "\n",
        "    x = jnp.tanh(self.final_conv(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NSrXfgrrAEBZ"
      },
      "outputs": [],
      "source": [
        "def tree_shape(xs):\n",
        "  return jax.tree_util.tree_map(lambda x: x.shape, xs)\n",
        "\n",
        "class InterpolatorState(NamedTuple):\n",
        "  params: Any\n",
        "  states: Any\n",
        "  opt_state: Any\n",
        "\n",
        "def MSSSIML1_loss_vectorized(image1, image2, sigmas=(0.5, 1., 2., 4., 8.), filter_size=11, C1=.01, C2=.03, alpha=0.84):\n",
        "  # image1 and image2 are the same shape Nx1xHxWxC and are floats in the range [-1.0, 1.0]\n",
        "  ## experiment with different alpha values (maybe adjust the alpha at a certain iteration?)\n",
        "  ## L2 instead of L1 would be an interesting test that's easy to implement\n",
        "  C1 = C1**2\n",
        "  C2 = C2**2\n",
        "  num_scale = len(sigmas)\n",
        "  batch = image1.shape[0]\n",
        "  channels = image1.shape[4]\n",
        "  height = image1.shape[2]\n",
        "  width = image1.shape[3]\n",
        "  image1 = jnp.moveaxis(jnp.reshape(image1, (batch, height, width, channels)), 3, 1)\n",
        "  image2 = jnp.moveaxis(jnp.reshape(image2, (batch, height, width, channels)), 3, 1)\n",
        "  image1 = (image1+1)/2\n",
        "  image2 = (image2+1)/2\n",
        "  image1 = jnp.reshape(image1, (batch*channels, height, width, 1))\n",
        "  image2 = jnp.reshape(image2, (batch*channels, height, width, 1))\n",
        "  diff = jnp.abs(image2-image1)\n",
        "  width = filter_size\n",
        "\n",
        "  # initialize the gaussian filters based on the bottom size\n",
        "  w = jnp.exp((-1.*jnp.arange(-(width//2), width//2+1)**2)[None,:] / (2*jnp.array(sigmas)**2)[:,None])\n",
        "  w = w[:,:,None]@w[:,None,:]\n",
        "  w = w / jnp.sum(w, axis=(1,2))[:,None,None]\n",
        "  w = jnp.reshape(w, (num_scale, 1, width, width))\n",
        "  w = jnp.transpose(w, axes=(3,2,1,0))\n",
        "\n",
        "  w = jnp.transpose(w,[3,2,0,1])\n",
        "  image1 = jnp.transpose(image1,[0,3,1,2])\n",
        "  image2 = jnp.transpose(image2,[0,3,1,2])\n",
        "  \n",
        "  mux = jax.lax.conv(image1, w, (1,1), \"SAME\")\n",
        "  muy = jax.lax.conv(image2, w, (1,1), \"SAME\")\n",
        "  sigmax2 = jax.lax.conv(image1**2, w, (1,1), \"SAME\") - mux **2\n",
        "  sigmay2 = jax.lax.conv(image2**2, w, (1,1), \"SAME\") - muy **2\n",
        "  sigmaxy = jax.lax.conv(image1*image2, w, (1,1), \"SAME\") - mux * muy\n",
        "  l = (2 * mux * muy + C1)/(mux ** 2 + muy **2 + C1)\n",
        "  cs = (2 * sigmaxy + C2)/(sigmax2 + sigmay2 + C2)\n",
        "\n",
        "  Pcs = jnp.prod(cs, axis=1)\n",
        "  # this is the l1_loss weighted by the gaussian\n",
        "  l1_loss = jnp.mean(jax.lax.conv(jnp.transpose(diff,[0,3,1,2]), w[-1,:,:,:][None,:,:,:], (1,1), \"SAME\"))\n",
        "  \n",
        "  return alpha * (1 - jnp.mean(l[:, -1, :, :] * Pcs)) + (1 - alpha) * l1_loss\n",
        "\n",
        "class FrameInterpolator:\n",
        "\n",
        "  def __init__(self, is_training):\n",
        "  \n",
        "    # Define the Haiku network transforms.\n",
        "    # We don't use BatchNorm so we don't use `with_state`.\n",
        "    self.gen_transform = hk.without_apply_rng(\n",
        "        hk.transform_with_state(lambda *args: ImageGenerator(is_training)(*args)))\n",
        "    \n",
        "    # Build the optimizers.\n",
        "    total_steps = 1800 ## Total Batches\n",
        "    scheduler = optax.cosine_decay_schedule(1e-3, decay_steps=total_steps, alpha=0.95)\n",
        "\n",
        "    # Combining gradient transforms using `optax.chain`.\n",
        "    ## using SGD instead of adam might help for generalization\n",
        "    self.optimizer = optax.chain(\n",
        "        optax.clip_by_global_norm(1.0),  # Clip by the gradient by the global norm.\n",
        "        optax.scale_by_adam(),  # Use the updates from adam.\n",
        "        optax.scale_by_schedule(scheduler),  # Use the learning rate from the scheduler.\n",
        "        # Scale updates by -1 since optax.apply_updates is additive and we want to descend on the loss.\n",
        "        optax.scale(-1.0)\n",
        "    )\n",
        "\n",
        "  @partial(jax.jit, static_argnums=0)\n",
        "  def initial_state(self, rng, surrounding_frames, goal_frames):\n",
        "    \"\"\"Returns the initial parameters and optimize states.\"\"\"\n",
        "    # Generate dummy latents for the generator.\n",
        "    dummy_surrounding_frames, dummy_goal_frames = jnp.ones(surrounding_frames.shape), jnp.ones(goal_frames.shape)\n",
        "\n",
        "    gen_params, gen_state = self.gen_transform.init(rng, dummy_surrounding_frames)\n",
        "    print(\"Generator: \\n\\n{}\\n\".format(tree_shape(gen_params)))\n",
        "    \n",
        "    # Initialize the optimizers.\n",
        "    gen_opt_state = self.optimizer.init(gen_params)\n",
        "    \n",
        "    return InterpolatorState(params=gen_params, states=gen_state, opt_state=gen_opt_state)\n",
        "\n",
        "  def create_image(self, gen_params, gen_state, surrounding_frames):\n",
        "    \"\"\"Generates images from noise latents.\"\"\"\n",
        "    return self.gen_transform.apply(gen_params, gen_state, surrounding_frames)\n",
        "    \n",
        "  def gen_loss(self, gen_params, gen_state, surrounding_frames, goal_frames):\n",
        "    \"\"\"Generator loss.\"\"\"\n",
        "    # Sample from the generator.\n",
        "    fake_batch, gen_state = self.create_image(gen_params, gen_state, surrounding_frames)\n",
        "\n",
        "    # Evaluate using the discriminator. Recall class 1 is real.\n",
        "    loss = MSSSIML1_loss_vectorized(fake_batch, goal_frames)\n",
        "    #loss = L1_loss(fake_batch, goal_frames)\n",
        "    return loss, (gen_state, fake_batch)\n",
        "\n",
        "  @partial(jax.jit, static_argnums=0)\n",
        "  def update_gen(self, interpolator_state, surrounding_frames, goal_frames):\n",
        "    # Update the generator.\n",
        "    (gen_loss, gen_loss_aux_output), gen_grads = jax.value_and_grad(self.gen_loss, has_aux=True)(\n",
        "        interpolator_state.params,\n",
        "        interpolator_state.states, \n",
        "        surrounding_frames,\n",
        "        goal_frames)\n",
        "    gen_update, gen_opt_state = self.optimizer.update(\n",
        "        gen_grads, interpolator_state.opt_state)\n",
        "    gen_params = optax.apply_updates(interpolator_state.params, gen_update)\n",
        "    interpolator_state = InterpolatorState(params=gen_params, states=gen_loss_aux_output[0], opt_state=gen_opt_state)\n",
        "    return interpolator_state, gen_loss, gen_loss_aux_output[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgX038Z9Iy4V"
      },
      "outputs": [],
      "source": [
        "num_steps = 1200\n",
        "log_every = 20\n",
        "\n",
        "# Display hardware\n",
        "print(f\"Number of devices: {jax.device_count()}\")\n",
        "print(\"Device:\", jax.devices()[0].device_kind)\n",
        "print(\"\")\n",
        "\n",
        "# The training dataset\n",
        "dataset = make_dataset(shuffle_amount=1)\n",
        "\n",
        "# Top-level RNG.\n",
        "rng = jax.random.PRNGKey(42)\n",
        "\n",
        "losses = []\n",
        "\n",
        "# dummy frames for init\n",
        "## using a different batch size would likely help\n",
        "surrounding_frames, goal_frames = make_batch(dataset, True, True, 1)\n",
        "\n",
        "# The model.\n",
        "interpolator = FrameInterpolator(is_training=True)\n",
        "\n",
        "# Initialize the network and optimizer.\n",
        "interpolator_state = interpolator.initial_state(rng, surrounding_frames, goal_frames)\n",
        "\n",
        "# if previous model is already saved\n",
        "#gen_params = restore(\"/content/gdrive/MyDrive/frame_interpolation/gen/params3\")\n",
        "#gen_state = restore(\"/content/gdrive/MyDrive/frame_interpolation/gen/model_state3\")\n",
        "#gen_opt_state = interpolator.optimizer.init(gen_params)\n",
        "#interpolator_state = InterpolatorState(params=gen_params, states=gen_state, opt_state=gen_opt_state)\n",
        "\n",
        "for step in range(0, num_steps+1):\n",
        "  ## using a different batch size would likely help\n",
        "  surrounding_frames, goal_frames = make_batch(dataset, True, True, 12)\n",
        "  interpolator_state, interpolator_loss, images_generated = interpolator.update_gen(interpolator_state, surrounding_frames, goal_frames)\n",
        "  losses.append(jax.device_get(interpolator_loss))\n",
        "  # Log the losses.\n",
        "  if step % log_every == 0:   \n",
        "    # It's important to call `device_get` here so we don't take up device\n",
        "    # memory by saving the losses.\n",
        "    interpolator_loss = jnp.mean(jnp.array(losses))\n",
        "    losses = []\n",
        "    print(f\"Step {step}: \"\n",
        "          f\"train loss = {interpolator_loss:.7f}\")\n",
        "\n",
        "\n",
        "  if step % (3*log_every) == 0:\n",
        "    #for visualizing one of the generated images\n",
        "    images_generated = jax.device_get(images_generated[0])\n",
        "    arr_ = np.squeeze((images_generated+1)/2)\n",
        "    plt.imshow(arr_)\n",
        "    plt.show()\n",
        "    #goal for comparision:\n",
        "    arr_ = np.squeeze((goal_frames[0,0,:,:,:]+1)/2)\n",
        "    plt.imshow(arr_)\n",
        "    plt.show()\n",
        "\n",
        "  if step % (6*log_every) == 0:\n",
        "    save(\"/content/gdrive/MyDrive/frame_interpolation/gen/params3\", jax.device_get(interpolator_state.params))\n",
        "    save(\"/content/gdrive/MyDrive/frame_interpolation/gen/model_state3\", jax.device_get(interpolator_state.states))\n",
        "    #for saving optimizer state (commented out because the file is >1GB)\n",
        "    #with open(os.path.join(\"/content/gdrive/MyDrive/frame_interpolation/gen/opt_state\", \"opt_state.pkl\"), \"wb\") as output_file:\n",
        "    #  pickle.dump(jax.device_get(interpolator_state.opt_state), output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adLBvbRytPwc"
      },
      "outputs": [],
      "source": [
        "interpolator = FrameInterpolator(is_training=False)\n",
        "gen_params = restore(\"/content/gdrive/MyDrive/frame_interpolation/gen/params3\")\n",
        "gen_state = restore(\"/content/gdrive/MyDrive/frame_interpolation/gen/model_state3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz998rQAft33"
      },
      "outputs": [],
      "source": [
        "# This is how I roughly checked for L1 contribution to the loss\n",
        "dataset = make_dataset(data, 1, 1)\n",
        "total_loss = 0\n",
        "for _ in range(60):\n",
        "  surrounding_frames, goal_frames = make_batch(dataset, True, True, 1, skip_prob=0)\n",
        "  pred_image, _ = interpolator.create_image(gen_params, gen_state, surrounding_frames, False)\n",
        "  total_loss += jnp.mean(jnp.abs(pred_image - goal_frames))\n",
        "print(total_loss/60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThMe02Z9I386"
      },
      "outputs": [],
      "source": [
        "#example of how to apply the model after training (will output vid in 256x256 pixels, so change the pixel sizes if using a different sized video):\n",
        "videodata = jnp.array(skvideo.io.vread(\"video.mp4\")) #change this to your video\n",
        "final_frames = jnp.empty((0, 256, 256, 3))\n",
        "for i in range(videodata.shape[0]-1):\n",
        "  surrounding_frames = videodata[i:i+2,:,:,:]/255.*2-1\n",
        "  crops = jnp.reshape(jnp.tile(jnp.array((0, 0, 1, 1)), 2), (2, 4))\n",
        "  surrounding_frames = tf.image.crop_and_resize(\n",
        "            surrounding_frames,\n",
        "            crops,\n",
        "            jnp.arange(2),\n",
        "            (256, 256)).numpy()\n",
        "  surrounding_frames = jnp.reshape(surrounding_frames, (1, 2, 256, 256, 3))\n",
        "  pred_image, _ = interpolator.create_image(interpolator_state.params, interpolator_state.states, surrounding_frames, False)\n",
        "  final_frames = jnp.concatenate([final_frames, surrounding_frames[0,0,:,:,:][None,:,:,:], pred_image[0]])\n",
        "  if i == videodata.shape[0]-2:\n",
        "    final_frames = jnp.concatenate([final_frames, surrounding_frames[0,1,:,:,:][None,:,:,:]])\n",
        "outputdata = (final_frames + 1)/2 * 255\n",
        "outputdata = outputdata.astype(jnp.uint8)\n",
        "\n",
        "writer = skvideo.io.FFmpegWriter(\"outputvideo.mp4\")\n",
        "for i in range(outputdata.shape[0]):\n",
        "  writer.writeFrame(outputdata[i, :, :, :])\n",
        "writer.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyNVgFxtZ2s39z8x5zwnoCSl",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}